{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "143a3b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),\n",
    "                                  columns=['dup_cnt'])\n",
    "    feature_dup_df = feature_dup_df.reset_index()\n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
    "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) \n",
    "                                                                                         if x[1] >0 else x[0] ,  axis=1)\n",
    "    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n",
    "    return new_feature_name_df\n",
    "\n",
    "def get_human_dataset( ):\n",
    "    \n",
    "    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
    "    feature_name_df = pd.read_csv('C:/ex1/uard/features.txt',sep='\\s+',\n",
    "                        header=None,names=['column_index','column_name'])\n",
    "    \n",
    "    # 중복된 피처명을 수정하는 get_new_feature_name_df()를 이용, 신규 피처명 DataFrame생성. \n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    # DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
    "    \n",
    "    # 학습 피처 데이터 셋과 테스트 피처 데이터을 DataFrame으로 로딩. 컬럼명은 feature_name 적용\n",
    "    X_train = pd.read_csv('C:/ex1/uard/train/X_train.txt',sep='\\s+', names=feature_name )\n",
    "    X_test = pd.read_csv('C:/ex1/uard/test/X_test.txt',sep='\\s+', names=feature_name)\n",
    "    \n",
    "    # 학습 레이블과 테스트 레이블 데이터을 DataFrame으로 로딩하고 컬럼명은 action으로 부여\n",
    "    y_train = pd.read_csv('C:/ex1/uard/train/y_train.txt',sep='\\s+',header=None,names=['action'])\n",
    "    y_test = pd.read_csv('C:/ex1/uard/test/y_test.txt',sep='\\s+',header=None,names=['action'])\n",
    "    \n",
    "    # 로드된 학습/테스트용 DataFrame을 모두 반환 \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ee0bc634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 학습 피처 데이터 정보 ##\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7352 entries, 0 to 7351\n",
      "Columns: 561 entries, tBodyAcc-mean()-X to angle(Z,gravityMean)\n",
      "dtypes: float64(561)\n",
      "memory usage: 31.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 결정 트리에서 사용한 get_human_dataset( )을 이용해 학습/테스트용 DataFrame 반환\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "print(\"## 학습 피처 데이터 정보 ##\")\n",
    "print(X_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bf11e5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SVM Classifier ---\n",
      "0.9504580929759077\n",
      "[[488   5   3   0   0   0]\n",
      " [ 20 451   0   0   0   0]\n",
      " [ 10  26 384   0   0   0]\n",
      " [  0   2   0 438  51   0]\n",
      " [  0   0   0  29 503   0]\n",
      " [  0   0   0   0   0 537]]\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_svm = SVC(random_state=0)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "pred_svm = clf_svm.predict(X_test)\n",
    "\n",
    "print(\"\\n--- SVM Classifier ---\")\n",
    "print(accuracy_score(y_test, pred_svm))\n",
    "print(confusion_matrix(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dc5207d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Logistic Regression Classifier ---\n",
      "0.9579233118425518\n",
      "[[492   1   3   0   0   0]\n",
      " [ 24 445   2   0   0   0]\n",
      " [  4  13 403   0   0   0]\n",
      " [  0   3   0 430  58   0]\n",
      " [  0   0   0  16 516   0]\n",
      " [  0   0   0   0   0 537]]\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_lr = LogisticRegression(random_state=0)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "pred_lr = clf_lr.predict(X_test)\n",
    "\n",
    "print (\"\\n--- Logistic Regression Classifier ---\")\n",
    "print (accuracy_score(y_test, pred_lr))\n",
    "print (confusion_matrix(y_test, pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8e2e0e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Decision Tree Classifier ---\n",
      "0.8595181540549711\n",
      "[[448  24  24   0   0   0]\n",
      " [ 74 367  30   0   0   0]\n",
      " [ 23  46 351   0   0   0]\n",
      " [  0   0   0 373 118   0]\n",
      " [  0   0   0  75 457   0]\n",
      " [  0   0   0   0   0 537]]\n"
     ]
    }
   ],
   "source": [
    "# DT\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dt = DecisionTreeClassifier(random_state=0)\n",
    "clf_dt.fit(X_train, y_train)\n",
    "\n",
    "pred_dt = clf_dt.predict(X_test)\n",
    "\n",
    "print (\"\\n--- Decision Tree Classifier ---\")\n",
    "print (accuracy_score(y_test, pred_dt))\n",
    "print (confusion_matrix(y_test, pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6896d1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Random Forest ---\n",
      "0.9253478113335596\n",
      "[[486   4   6   0   0   0]\n",
      " [ 38 426   7   0   0   0]\n",
      " [ 22  44 354   0   0   0]\n",
      " [  0   0   0 440  51   0]\n",
      " [  0   0   0  48 484   0]\n",
      " [  0   0   0   0   0 537]]\n"
     ]
    }
   ],
   "source": [
    "# RT\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "print (\"\\n--- Random Forest ---\")\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "print(accuracy_score(y_test,pred))\n",
    "print (confusion_matrix(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
